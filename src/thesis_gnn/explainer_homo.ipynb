{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702342c3-bc75-4cec-86cd-0ad0925b1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import time\n",
    "import logging\n",
    "from util import create_parser, set_seed, logger_setup\n",
    "from data_loading import get_data\n",
    "from training import train_gnn\n",
    "from inference import infer_gnn\n",
    "import json\n",
    "\n",
    "# copied from inference.py\n",
    "import torch\n",
    "import pandas as pd\n",
    "from train_util import AddEgoIds, extract_param, add_arange_ids, get_loaders, evaluate_homo\n",
    "from training import get_model\n",
    "from torch_geometric.nn import summary\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# coppied from train_util.py\n",
    "import tqdm\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from typing import Union\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "\n",
    "# Torch related library\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, PGExplainer\n",
    "\n",
    "\n",
    "script_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6e8375-aef4-431a-9c59-b4490c667de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create parcer\n",
    "debug_flags = [\n",
    "            \"--data\", \"Small_HI\",\n",
    "            \"--model\", \"dir_gin\",\n",
    "            \"--ego\",\n",
    "            \"--unique_name\", \"directed\",\n",
    "            \"--tqdm\",\n",
    "            \"--ports\",\n",
    "            \"--emlps\",\n",
    "        ]\n",
    "parser = create_parser()\n",
    "args = parser.parse_args(debug_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4325caba-7140-42f7-923a-be00f974fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_explanation_homo(loader, inds, model, data, device, args):\n",
    "    \"\"\"\n",
    "    Code is created based on evaluate_homo function in train_util.py\n",
    "    \"\"\"\n",
    "    for batch in tqdm.tqdm(loader, disable=not args.tqdm):\n",
    "        # Select the seed edges from which the batch was created\n",
    "        inds = inds.detach().cpu()\n",
    "        batch_edge_inds = inds[batch.input_id.detach().cpu()]\n",
    "        batch_edge_ids = loader.data.edge_attr.detach().cpu()[batch_edge_inds, 0]\n",
    "        mask = torch.isin(batch.edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n",
    "\n",
    "        #add the seed edges that have not been sampled to the batch\n",
    "        missing = ~torch.isin(batch_edge_ids, batch.edge_attr[:, 0].detach().cpu())\n",
    "\n",
    "        if missing.sum() != 0 and (args.data == 'Small_J' or args.data == 'Small_Q'):\n",
    "            missing_ids = batch_edge_ids[missing].int()\n",
    "            n_ids = batch.n_id\n",
    "            add_edge_index = data.edge_index[:, missing_ids].detach().clone()\n",
    "            node_mapping = {value.item(): idx for idx, value in enumerate(n_ids)}\n",
    "            add_edge_index = torch.tensor([[node_mapping[val.item()] for val in row] for row in add_edge_index])\n",
    "            add_edge_attr = data.edge_attr[missing_ids, :].detach().clone()\n",
    "            add_y = data.y[missing_ids].detach().clone()\n",
    "        \n",
    "            batch.edge_index = torch.cat((batch.edge_index, add_edge_index), 1)\n",
    "            batch.edge_attr = torch.cat((batch.edge_attr, add_edge_attr), 0)\n",
    "            batch.y = torch.cat((batch.y, add_y), 0)\n",
    "\n",
    "            mask = torch.cat((mask, torch.ones(add_y.shape[0], dtype=torch.bool)))\n",
    "\n",
    "        #remove the unique edge id from the edge features, as it's no longer needed\n",
    "        batch.edge_attr = batch.edge_attr[:, 1:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            out = out[mask]\n",
    "\n",
    "    return loader, inds, model, data, device, args, batch_edge_ids, batch_edge_inds, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd945559-2b64-4841-96ea-030cefcddb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, args, data_config):\n",
    "    \"\"\"\n",
    "    Code is created based on inference.py\n",
    "    \"\"\"\n",
    "    # set device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # define a model config dictionary and wandb logging at the same time\n",
    "    wandb.init(\n",
    "        mode=\"disabled\" if args.testing else \"online\",\n",
    "        project=\"explainability\",\n",
    "\n",
    "        config={\n",
    "            \"epochs\": args.n_epochs,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"model\": args.model,\n",
    "            \"data\": args.data,\n",
    "            \"num_neighbors\": args.num_neighs,\n",
    "            \"lr\": extract_param(\"lr\", args),\n",
    "            \"n_hidden\": extract_param(\"n_hidden\", args),\n",
    "            \"n_gnn_layers\": extract_param(\"n_gnn_layers\", args),\n",
    "            \"loss\": \"ce\",\n",
    "            \"w_ce1\": extract_param(\"w_ce1\", args),\n",
    "            \"w_ce2\": extract_param(\"w_ce2\", args),\n",
    "            \"dropout\": extract_param(\"dropout\", args),\n",
    "            \"final_dropout\": extract_param(\"final_dropout\", args),\n",
    "            \"n_heads\": extract_param(\"n_heads\", args) if args.model == 'gat' else None\n",
    "        }\n",
    "    )\n",
    "\n",
    "    config = wandb.config\n",
    "\n",
    "    # set the transform if ego ids should be used\n",
    "    if args.ego:\n",
    "        transform = AddEgoIds()\n",
    "    else:\n",
    "        transform = None\n",
    "\n",
    "    # add the unique ids to later find the seed edges\n",
    "    add_arange_ids([tr_data, val_data, te_data])\n",
    "\n",
    "    tr_loader, val_loader, te_loader = get_loaders(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, transform,\n",
    "                                                   args)\n",
    "\n",
    "    # get the model\n",
    "    sample_batch = next(iter(tr_loader))\n",
    "    model = get_model(sample_batch, config, args)\n",
    "\n",
    "    if args.reverse_mp:\n",
    "        model = to_hetero(model, te_data.metadata(), aggr='mean')\n",
    "\n",
    "    logging.info(\"=> loading model checkpoint\")\n",
    "    #todo: to avoid issue: hardcoding unique name as directed\n",
    "    checkpoint = torch.load(f'{data_config[\"paths\"][\"model_to_load\"]}/checkpoint_directed.tar') \n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "\n",
    "    logging.info(\"=> loaded checkpoint (epoch {})\".format(start_epoch))\n",
    "\n",
    "    \n",
    "    if not args.reverse_mp:\n",
    "        te_loader, te_inds, model, te_data, device, args, batch_edge_ids, batch_edge_inds, batch = prep_explanation_homo(te_loader, te_inds, model, te_data, device, args)\n",
    "    else:\n",
    "        te_loader, te_inds, model, te_data, device, args, batch_edge_ids, batch_edge_inds, batch = prep_explanation(te_loader, te_inds, model, te_data, device, args)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return te_loader, te_inds, model, te_data, device, args, batch_edge_ids, batch_edge_inds, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91e4f55-5fde-4de8-bf5f-290b5ce28bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-08 16:24:57,469 [INFO ] Random seed set as 1\n",
      "2025-06-08 16:24:57,470 [INFO ] Retrieving data\n",
      "üîç inside of get_data: data_config[paths][aml_data] = kaggle-files\n",
      "üîç inside of get_data: --data passed in as        = Small_HI\n",
      "   EdgeID  from_id  to_id  Timestamp  Amount Sent  Sent Currency  \\\n",
      "0       2        3      3         10     14675.57              0   \n",
      "1      17       24     24         10       897.37              0   \n",
      "2     158      163    163         10     99986.94              0   \n",
      "3     218      215    215         10        16.08              0   \n",
      "4     281      265    265         10        10.30              0   \n",
      "\n",
      "   Amount Received  Received Currency  Payment Format  Is Laundering  \n",
      "0         14675.57                  0               0              0  \n",
      "1           897.37                  0               0              0  \n",
      "2         99986.94                  0               0              0  \n",
      "3            16.08                  0               0              0  \n",
      "4            10.30                  0               0              0  \n",
      "2025-06-08 16:25:01,128 [INFO ] Available Edge Features: ['EdgeID', 'from_id', 'to_id', 'Timestamp', 'Amount Sent', 'Sent Currency', 'Amount Received', 'Received Currency', 'Payment Format', 'Is Laundering']\n",
      "2025-06-08 16:25:56,732 [INFO ] Illicit ratio = 5177 / 5078345 = 0.10%\n",
      "2025-06-08 16:25:56,733 [INFO ] Number of nodes (holdings doing transcations) = 515088\n",
      "2025-06-08 16:25:56,735 [INFO ] Number of transactions = 5078345\n",
      "2025-06-08 16:25:56,736 [INFO ] Edge features being used: ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format']\n",
      "2025-06-08 16:25:56,737 [INFO ] Node features being used: ['Feature'] (\"Feature\" is a placeholder feature of all 1s)\n",
      "2025-06-08 16:25:56,946 [INFO ] number of days and transactions in the data: 18 days, 5078345 transactions\n",
      "done process1\n",
      "2025-06-08 16:25:57,103 [INFO ] Calculate split: [[0, 1, 2, 3, 4, 5], [6, 7], [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n",
      "done process2\n",
      "2025-06-08 16:25:57,126 [INFO ] Total train samples: 63.98% || IR: 0.08% || Train days: [0, 1, 2, 3, 4]\n",
      "2025-06-08 16:25:57,130 [INFO ] Total val samples: 19.01% || IR: 0.11% || Val days: [6, 7]\n",
      "2025-06-08 16:25:57,135 [INFO ] Total test samples: 17.01% || IR: 0.19% || Test days: [8, 9, 10, 11, 12]\n",
      "done process3\n",
      "2025-06-08 16:25:57,232 [INFO ] Start: adding ports\n",
      "2025-06-08 16:37:41,721 [INFO ] Done: adding ports\n",
      "done process4\n",
      "2025-06-08 16:37:42,928 [INFO ] train data object: GraphData(x=[515088, 1], edge_index=[2, 3248921], edge_attr=[3248921, 6], y=[3248921], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[3248921])\n",
      "2025-06-08 16:37:42,929 [INFO ] validation data object: GraphData(x=[515088, 1], edge_index=[2, 4214445], edge_attr=[4214445, 6], y=[4214445], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[4214445])\n",
      "2025-06-08 16:37:42,929 [INFO ] test data object: GraphData(x=[515088, 1], edge_index=[2, 5078345], edge_attr=[5078345, 6], y=[5078345], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[5078345])\n",
      "2025-06-08 16:37:42,948 [INFO ] Retrieved data in 765.48s\n",
      "2025-06-08 16:37:42,949 [INFO ] Running Explanation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: kmishik (kmishik-university-of-bath) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ishik\\OneDrive\\OneNote_Uploads\\Documents\\GitHub\\Thesis_Multi_GNN\\wandb\\run-20250608_163744-kyazcw4k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kmishik-university-of-bath/explainability/runs/kyazcw4k' target=\"_blank\">lemon-sponge-71</a></strong> to <a href='https://wandb.ai/kmishik-university-of-bath/explainability' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kmishik-university-of-bath/explainability' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kmishik-university-of-bath/explainability/runs/kyazcw4k' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability/runs/kyazcw4k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-08 16:37:47,323 [INFO ] => loading model checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishik\\AppData\\Local\\Temp\\ipykernel_11528\\2379049112.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'{data_config[\"paths\"][\"model_to_load\"]}/checkpoint_directed.tar')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-08 16:37:47,874 [INFO ] => loaded checkpoint (epoch 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 106/106 [02:33<00:00,  1.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sponge-71</strong> at: <a href='https://wandb.ai/kmishik-university-of-bath/explainability/runs/kyazcw4k' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability/runs/kyazcw4k</a><br> View project at: <a href='https://wandb.ai/kmishik-university-of-bath/explainability' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250608_163744-kyazcw4k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data_config.json', 'r') as config_file:\n",
    "    data_config = json.load(config_file)\n",
    "\n",
    "# Setup logging\n",
    "logger_setup()\n",
    "\n",
    "#set seed\n",
    "set_seed(args.seed)\n",
    "\n",
    "#get data\n",
    "logging.info(\"Retrieving data\")\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "tr_data, val_data, te_data, tr_inds, val_inds, te_inds = get_data(args, data_config)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "logging.info(f\"Retrieved data in {t2-t1:.2f}s\")\n",
    "\n",
    "\n",
    "logging.info(f\"Running Explanation\")\n",
    "#todo: data, inds of tr, val needed?\n",
    "te_loader, te_inds, model, te_data, device, args, batch_edge_ids, batch_edge_inds, batch = load_trained_model(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, args, data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6cfda-9cfb-45bb-84d3-563676c8f92d",
   "metadata": {},
   "source": "## Below code will raise an error as attribute for edge_mask_type is not currently supported."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74bd7637-5f2f-4e39-8d63-514a01bcfb1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'attribute' is not a valid MaskType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m explainer \u001B[38;5;241m=\u001B[39m \u001B[43mExplainer\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                       \u001B[49m\u001B[43malgorithm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mGNNExplainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m       \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mnum_hops\u001B[49m\u001B[43m     \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                         \u001B[49m\u001B[43medge_size\u001B[49m\u001B[43m    \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m        \u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mentropy_reg\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mexplanation_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# skip node_mask_type (will set as NA) as node feature is added only for processing purpose.\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m                       \u001B[49m\u001B[43medge_mask_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mattribute\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbinary_classification\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mtask_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43medge\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mreturn_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mraw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                       \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis-torch26-modified\\lib\\site-packages\\torch_geometric\\explain\\explainer.py:79\u001B[0m, in \u001B[0;36mExplainer.__init__\u001B[1;34m(self, model, algorithm, explanation_type, model_config, node_mask_type, edge_mask_type, threshold_config)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     71\u001B[0m     model: torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     77\u001B[0m     threshold_config: Optional[ThresholdConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     78\u001B[0m ):\n\u001B[1;32m---> 79\u001B[0m     explainer_config \u001B[38;5;241m=\u001B[39m \u001B[43mExplainerConfig\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexplanation_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexplanation_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnode_mask_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode_mask_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_mask_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_mask_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgorithm \u001B[38;5;241m=\u001B[39m algorithm\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis-torch26-modified\\lib\\site-packages\\torch_geometric\\explain\\config.py:96\u001B[0m, in \u001B[0;36mExplainerConfig.__init__\u001B[1;34m(self, explanation_type, node_mask_type, edge_mask_type)\u001B[0m\n\u001B[0;32m     94\u001B[0m     node_mask_type \u001B[38;5;241m=\u001B[39m MaskType(node_mask_type)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edge_mask_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     edge_mask_type \u001B[38;5;241m=\u001B[39m \u001B[43mMaskType\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_mask_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edge_mask_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m edge_mask_type \u001B[38;5;241m!=\u001B[39m MaskType\u001B[38;5;241m.\u001B[39mobject:\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_mask_type\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m needs be None or of type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    100\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00medge_mask_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis-torch26-modified\\lib\\enum.py:384\u001B[0m, in \u001B[0;36mEnumMeta.__call__\u001B[1;34m(cls, value, names, module, qualname, type, start)\u001B[0m\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;124;03mEither returns an existing member, or creates a new enum class.\u001B[39;00m\n\u001B[0;32m    361\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;124;03m`type`, if set, will be mixed in as the first base class.\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# simple value lookup\u001B[39;00m\n\u001B[1;32m--> 384\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__new__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001B[39;00m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_create_(\n\u001B[0;32m    387\u001B[0m         value,\n\u001B[0;32m    388\u001B[0m         names,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    392\u001B[0m         start\u001B[38;5;241m=\u001B[39mstart,\n\u001B[0;32m    393\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\thesis-torch26-modified\\lib\\enum.py:702\u001B[0m, in \u001B[0;36mEnum.__new__\u001B[1;34m(cls, value)\u001B[0m\n\u001B[0;32m    700\u001B[0m ve_exc \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m is not a valid \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (value, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m))\n\u001B[0;32m    701\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 702\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ve_exc\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    704\u001B[0m     exc \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    705\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124merror in \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m._missing_: returned \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m instead of None or a valid member\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    706\u001B[0m             \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, result)\n\u001B[0;32m    707\u001B[0m             )\n",
      "\u001B[1;31mValueError\u001B[0m: 'attribute' is not a valid MaskType"
     ]
    }
   ],
   "source": [
    "import math\n",
    "explainer = Explainer (model=model,\n",
    "                       algorithm=GNNExplainer(\n",
    "                         epochs       = 300,\n",
    "                         num_hops     = 3,  \n",
    "                         edge_size    = math.inf,        \n",
    "                         entropy_reg  = 0.0),\n",
    "                       explanation_type=\"model\", # skip node_mask_type (will set as NA) as node feature is added only for processing purpose.\n",
    "                       edge_mask_type=\"attribute\",\n",
    "                       model_config=dict(\n",
    "                           mode=\"binary_classification\",\n",
    "                           task_level=\"edge\",\n",
    "                           return_type=\"raw\"\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7d443d-2215-4e59-89ea-6720dea6092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "explainer = Explainer (model=model,\n",
    "                       algorithm=GNNExplainer(\n",
    "                         epochs       = 300,\n",
    "                         num_hops     = 3,  \n",
    "                         edge_size    = math.inf,        \n",
    "                         entropy_reg  = 0.0),\n",
    "                       explanation_type=\"model\", # skip node_mask_type (will set as NA) as node feature is added only for processing purpose.\n",
    "                       edge_mask_type=\"object\",\n",
    "                       model_config=dict(\n",
    "                           mode=\"binary_classification\",\n",
    "                           task_level=\"edge\",\n",
    "                           return_type=\"raw\"\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90943574-9d35-446e-9340-efbf422ef645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['edge_mask']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "explanation = explainer(\n",
    "    batch.x,\n",
    "    batch.edge_index,\n",
    "    edge_attr=batch.edge_attr,\n",
    ")\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47515c3-a838-4be7-b2fc-68c2be177769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import fidelity, fidelity_curve_auc\n",
    "pos_fidelity, neg_fidelity = fidelity(explainer, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "168df2bd-07e4-4dd7-8934-8fcf9fe4bd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.501678466796875, 0.501678466796875)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_fidelity, neg_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6c9b50-1c27-4afc-9eda-ecc6d54b151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(x=[17844, 2], edge_index=[2, 162346], edge_attr=[162346, 6], y=[162346], readout='edge', loss_fn='ce', num_nodes=17844, timestamps=[162346], n_id=[17844], e_id=[162346], input_id=[3740], edge_label_index=[2, 3740], edge_label=[3740])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4adaae-e978-4c85-b6ef-a0c26f30b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481 / 162346 edges (0.009122491468838161%) are labelled 'laundering'. \n"
     ]
    }
   ],
   "source": [
    "# How many laundering edges in this batch.\n",
    "num_illicit = int(batch.y.sum())\n",
    "print(f\"{num_illicit} / {batch.y.numel()} edges ({num_illicit/batch.y.numel()}%) are labelled 'laundering'. \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac3900-a42e-4dbb-b8bb-ba01fd7666e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
