{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb69461-1032-4762-a41c-a8258f631744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reload_model import reload_main\n",
    "from util import create_parser, set_seed, logger_setup\n",
    "from explainer_algo import GNNExplainerEdgeFeature, make_attr_explainer, make_common_attr_explainer\n",
    "from itertools import product\n",
    "\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, ModelConfig, ExplainerConfig\n",
    "from torch_geometric.explain.config import MaskType, ModelMode\n",
    "from torch_geometric.explain.algorithm.utils import clear_masks, set_masks\n",
    "from torch_geometric.explain import fidelity, fidelity_curve_auc\n",
    "\n",
    "from fidelity_custom import fidelity_edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916af154-1fb6-4926-9f7b-ae577fc4968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create parcer\n",
    "flags = [\n",
    "            \"--data\", \"Small_HI\",\n",
    "            \"--model\", \"dir_gin\",\n",
    "            \"--ego\",\n",
    "            \"--unique_name\", \"directed_9Jun\",\n",
    "            \"--tqdm\",\n",
    "            \"--ports\",\n",
    "            \"--emlps\",\n",
    "        ]\n",
    "parser = create_parser()\n",
    "args = parser.parse_args(flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58292326-de02-4968-881a-a544fda83082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-16 21:23:17,275 [INFO ] Random seed set as 1\n",
      "2025-06-16 21:23:17,277 [INFO ] Retrieving data\n",
      "2025-06-16 21:23:19,783 [INFO ] Available Edge Features: ['EdgeID', 'from_id', 'to_id', 'Timestamp', 'Amount Sent', 'Sent Currency', 'Amount Received', 'Received Currency', 'Payment Format', 'Is Laundering']\n",
      "2025-06-16 21:24:02,689 [INFO ] Illicit ratio = 5177 / 5078345 = 0.10%\n",
      "2025-06-16 21:24:02,691 [INFO ] Number of nodes (holdings doing transcations) = 515088\n",
      "2025-06-16 21:24:02,691 [INFO ] Number of transactions = 5078345\n",
      "2025-06-16 21:24:02,692 [INFO ] Edge features being used: ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format']\n",
      "2025-06-16 21:24:02,693 [INFO ] Node features being used: ['Feature'] (\"Feature\" is a placeholder feature of all 1s)\n",
      "2025-06-16 21:24:03,190 [INFO ] number of days and transactions in the data: 18 days, 5078345 transactions\n",
      "2025-06-16 21:24:03,340 [INFO ] Calculate split: [[0, 1, 2, 3, 4, 5], [6, 7], [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]\n",
      "2025-06-16 21:24:03,364 [INFO ] Total train samples: 63.98% || IR: 0.08% || Train days: [0, 1, 2, 3, 4]\n",
      "2025-06-16 21:24:03,368 [INFO ] Total val samples: 19.01% || IR: 0.11% || Val days: [6, 7]\n",
      "2025-06-16 21:24:03,371 [INFO ] Total test samples: 17.01% || IR: 0.19% || Test days: [8, 9, 10, 11, 12]\n",
      "2025-06-16 21:24:03,476 [INFO ] Start: adding ports\n",
      "2025-06-16 21:32:22,283 [INFO ] Done: adding ports\n",
      "2025-06-16 21:32:23,145 [INFO ] train data object: GraphData(x=[515088, 1], edge_index=[2, 3248921], edge_attr=[3248921, 6], y=[3248921], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[3248921])\n",
      "2025-06-16 21:32:23,146 [INFO ] validation data object: GraphData(x=[515088, 1], edge_index=[2, 4214445], edge_attr=[4214445, 6], y=[4214445], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[4214445])\n",
      "2025-06-16 21:32:23,146 [INFO ] test data object: GraphData(x=[515088, 1], edge_index=[2, 5078345], edge_attr=[5078345, 6], y=[5078345], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[5078345])\n",
      "2025-06-16 21:32:23,156 [INFO ] Retrieved data in 545.88s\n",
      "2025-06-16 21:32:23,157 [INFO ] Running Explanation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: kmishik (kmishik-university-of-bath) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ishik\\OneDrive\\OneNote_Uploads\\Documents\\GitHub\\Thesis_Multi_GNN\\wandb\\run-20250616_213224-34kz4pjq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kmishik-university-of-bath/explainability/runs/34kz4pjq' target=\"_blank\">ancient-leaf-87</a></strong> to <a href='https://wandb.ai/kmishik-university-of-bath/explainability' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kmishik-university-of-bath/explainability' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kmishik-university-of-bath/explainability/runs/34kz4pjq' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability/runs/34kz4pjq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-16 21:32:27,929 [INFO ] => loading model checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishik\\OneDrive\\OneNote_Uploads\\Documents\\GitHub\\Thesis_Multi_GNN\\reload_model.py:130: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'{data_config[\"paths\"][\"model_to_load\"]}/checkpoint_{args.unique_name}.tar')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-16 21:32:28,108 [INFO ] => loaded checkpoint (epoch 35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:29<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batch is 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:29<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batch is 118\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-leaf-87</strong> at: <a href='https://wandb.ai/kmishik-university-of-bath/explainability/runs/34kz4pjq' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability/runs/34kz4pjq</a><br> View project at: <a href='https://wandb.ai/kmishik-university-of-bath/explainability' target=\"_blank\">https://wandb.ai/kmishik-university-of-bath/explainability</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250616_213224-34kz4pjq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parts_dict = reload_main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee034b1-6c83-4330-ac34-149d238cda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: treat edge as an object.\n",
    "explainer_obj = Explainer(model=parts_dict[\"model\"],\n",
    "                          algorithm=GNNExplainer(\n",
    "                              epochs       = 200,\n",
    "                              lr           = 0.01, \n",
    "                              num_hops     = 4,  \n",
    "                              edge_size    = 1.0,        \n",
    "                              entropy_reg  = 0.1,\n",
    "                          ),\n",
    "                          node_mask_type   = \"object\", \n",
    "                          explanation_type = \"model\", \n",
    "                          edge_mask_type   = \"object\",\n",
    "                          model_config     = dict(\n",
    "                              mode         = \"binary_classification\",\n",
    "                              task_level   = \"edge\",\n",
    "                              return_type  = \"raw\",\n",
    "                          )\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29919d6c-1a6b-4442-9e2c-d600f698c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated explanations in ['node_mask', 'edge_mask']\n"
     ]
    }
   ],
   "source": [
    "explanation_obj = explainer_obj(\n",
    "    parts_dict[\"te_batch\"].x,\n",
    "    parts_dict[\"te_batch\"].edge_index,\n",
    "    edge_attr =parts_dict[\"te_batch\"].edge_attr,\n",
    "    # target    =parts_dict[\"te_batch\"].y\n",
    ")\n",
    "print(f'Generated explanations in {explanation_obj.available_explanations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c419117c-6ed5-47c4-b03f-7c2c5e365efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0006189942359924316, 0.0039237141609191895)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fidelity(explainer_obj, explanation_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4496a6c-1c13-4d68-9c8c-011384a1df4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain import unfaithfulness\n",
    "\n",
    "metric = unfaithfulness(explainer_obj, explanation_obj)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72bef1c-e01b-4c86-952e-6dcc72980d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge mask on attribute level\n",
    "algo = GNNExplainerEdgeFeature(epochs=100, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7893a797-7f8e-4288-a88a-ca468c86ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_cfg = ModelConfig(\n",
    "    mode=\"multiclass_classification\", # to accept tensor is this okay?\n",
    "    task_level=\"edge\",\n",
    "    return_type=\"raw\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49cebac4-ae10-4781-9544-38127ef52d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fidelity on a object level for eddge: 0.0026239752769470215, 0.005087852478027344\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain import Explainer, fidelity\n",
    "from torch_geometric.explain.config import MaskType, ModelConfig\n",
    "explainer = Explainer(\n",
    "    model            = parts_dict[\"model\"],\n",
    "    algorithm        = algo,                # same instance as before\n",
    "    explanation_type = \"model\",\n",
    "    node_mask_type   = MaskType.object,\n",
    "    edge_mask_type   = \"object\",            # guard\n",
    "    model_config     = mdl_cfg,\n",
    ")\n",
    "explainer.algorithm._explainer_config.edge_mask_type = MaskType.attributes\n",
    "\n",
    "explanation = explainer(\n",
    "    x=parts_dict[\"te_batch\"].x, edge_index=parts_dict[\"te_batch\"].edge_index,\n",
    "    edge_attr=parts_dict[\"te_batch\"].edge_attr, )\n",
    "    #target=parts_dict[\"te_batch\"].y)\n",
    "\n",
    "# built-in metric works because edge_mask is 1-D\n",
    "fid_pos, fid_neg = fidelity(explainer, explanation)\n",
    "print(f'fidelity on a object level for eddge: {fid_pos}, {fid_neg}')\n",
    "\n",
    "# The full matrix for visualisation\n",
    "edge_feat = explanation.edge_feat_mask \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d62091-a885-4193-bbd9-adbb48d323c8",
   "metadata": {},
   "source": [
    "# Fedility with edge attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef01fc0-13ea-4246-bfa2-8253488cf773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DirGINe(\n",
       "  (node_emb): Linear(in_features=2, out_features=66, bias=True)\n",
       "  (edge_emb): Linear(in_features=6, out_features=66, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0-1): 2 x DirGINEWrapper(GINEConv(nn=Sequential(\n",
       "      (0): Linear(in_features=66, out_features=66, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )), alpha=0.5)\n",
       "  )\n",
       "  (emlps): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): Linear(in_features=198, out_features=66, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=66, out_features=66, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (batch_norms): ModuleList(\n",
       "    (0-1): 2 x BatchNorm(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(198, 50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.10527690625126304, inplace=False)\n",
       "    (3): Linear(50, 25, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.10527690625126304, inplace=False)\n",
       "    (6): Linear(25, 2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1ed1d1-eef3-4b84-a189-97f697467807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.007391571998596191, 0.002808809280395508)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fidelity_edge_attr(explainer, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af7ee8-60ee-463d-b9ed-4e127cfe89c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeffe53-4a12-46b1-8c61-135ca3346a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f6a46-4f10-4ad4-bb04-1b996469efcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1ee94-9049-43f5-90ba-a6f6245d2b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
